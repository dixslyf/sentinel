{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fine-Tuning and Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "from typing import Optional\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import fiftyone as fo\n",
    "import matplotlib.pyplot as plt\n",
    "import pymongo\n",
    "import yaml\n",
    "from roboflow import Roboflow\n",
    "from roboflow.core.dataset import Dataset as RoboflowDataset\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder paths.\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd()))\n",
    "IMAGES_PATH = os.path.join(ROOT_PATH, 'images')\n",
    "\n",
    "# Format to use when downloading Roboflow datasets.\n",
    "RF_DATASET_FORMAT = \"yolov8\"\n",
    "\n",
    "# Format to use when downloading FiftyOne datasets.\n",
    "FO_DATASET_FORMAT = fo.types.YOLOv5Dataset # YOLOv5 and YOLOv8 use the same format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FiftyOne uses MongoDB to manage its datasets. When possible, FiftyOne will automatically set up the database for you. However, when it fails to do so, you need to manually set up a MongoDB database. The code below checks if FiftyOne is able to set up the database — if not, then you must set up your own and specify the connection string. After installing MongoDB, run `mongod --dbpath <DBPATH>`, replacing `DBPATH` with any path of your choice. By default (no authentication and using the default port), the connection string is: `mongodb://localhost:27017`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        print(\"Trying to reach MongoDB...\")\n",
    "        fo.core.odm.database.get_db_config()\n",
    "        print(\"MongoDB is reachable.\")\n",
    "        break\n",
    "    except (fo.core.config.FiftyOneConfigError, pymongo.errors.ServerSelectionTimeoutError):\n",
    "        print(\"Failed to reach a running MongoDB instance. Enter a valid MongoDB connection string:\")\n",
    "        db_uri = input()\n",
    "        fo.config.database_uri = db_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to `gitignore` a directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gitignore(directory: str):\n",
    "    \"\"\"\n",
    "    Make the given directory ignored by Git.\n",
    "\n",
    "    No prefixes are prepended to the directory. The directory must already exist.\n",
    "\n",
    "    This function adds a `.gitignore` file to the directory\n",
    "    containing the wildcard pattern \"*\" so that git ignores it.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(directory):\n",
    "        raise ValueError(\"The given path does not exist or is not a directory.\")\n",
    "        \n",
    "    gitignore_path = os.path.join(directory, \".gitignore\")\n",
    "    with open(gitignore_path, \"w\") as gitignore_file:\n",
    "        gitignore_file.write(\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create the `IMAGES_PATH` directory early to make `git` ignore it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGES_PATH):\n",
    "    os.makedirs(IMAGES_PATH)\n",
    "    print(f\"Created '{IMAGES_PATH}' directory.\")\n",
    "else:\n",
    "    print(f\"'{IMAGES_PATH}' exists — nothing to do.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(IMAGES_PATH, \".gitignore\")):\n",
    "    gitignore(IMAGES_PATH)\n",
    "    print(f\"Gitignored '{IMAGES_PATH}'.\")\n",
    "else:\n",
    "    print(f\"'{IMAGES_PATH}/.gitignore' exists — skipping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roboflow Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download datasets from Roboflow, you must have a Roboflow API key. This notebook will attempt to load the API key from the `ROBOFLOW_API_KEY` environment variable. If the variable does not exist, then you will be prompted for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"ROBOFLOW_API_KEY\" not in os.environ:\n",
    "    print(\"Could not find Roboflow API key from environment.\")\n",
    "    print(\"Please enter your Roboflow API key: \")\n",
    "    rf_api_key = input()\n",
    "else:\n",
    "    rf_api_key = os.environ[\"ROBOFLOW_API_KEY\"]\n",
    "\n",
    "rf = Roboflow(api_key=rf_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_roboflow_dataset(workspace: str, project: str, version: str, directory: str, dataset_format=RF_DATASET_FORMAT):\n",
    "    \"\"\"\n",
    "    Downloads the specified Roboflow dataset into the given directory\n",
    "    and returns the dataset as a Roboflow `Dataset` object.\n",
    "\n",
    "    The directory will be prefixed by `IMAGES_PATH`.\n",
    "\n",
    "    If the directory already exists, the dataset will not be redownloaded.\n",
    "    \"\"\"\n",
    "    abs_directory = os.path.join(IMAGES_PATH, directory)\n",
    "\n",
    "    rf_project = rf.workspace(workspace).project(project)\n",
    "    rf_version = rf_project.version(version)\n",
    "    \n",
    "    if os.path.exists(abs_directory):\n",
    "        print(f\"Path '{abs_directory}' exists — refusing to overwrite.\")\n",
    "        print(\"If you want to redownload the dataset, please manually remove the directory.\")\n",
    "        return RoboflowDataset(rf_version.name, rf_version.version, dataset_format, abs_directory)\n",
    "        \n",
    "    dataset = rf_version.download(dataset_format, location=abs_directory)\n",
    "\n",
    "    print(f\"Dataset downloaded to: {abs_directory}\")\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gun_ds = download_roboflow_dataset(\"liteye-systems\", \"weapon-classification\", \"2\", \"guns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_coco2017(\n",
    "    categories: Optional[list[str]] = [\"person\"],\n",
    "    max_samples: Optional[int] = None,\n",
    "    directory: str = \"coco-2017\",\n",
    "    dataset_format=FO_DATASET_FORMAT,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Downloads the COCO 2017 dataset into the given directory.\n",
    "\n",
    "    All splits will be downloaded. The dataset can be filtered by category\n",
    "    using the `categories` argument. If `max_samples` is specified, then each\n",
    "    split will be limited to have a maximum of `max_samples` number of samples.\n",
    "    \n",
    "    By default, the dataset will be exported in the format specified by `FO_DATASET_FORMAT`.\n",
    "    To change the output format, specify the `dataset_format` argument.\n",
    "    \"\"\"\n",
    "    splits = [\"train\", \"test\", \"validation\"]\n",
    "    \n",
    "    dataset = fo.zoo.load_zoo_dataset(\n",
    "        \"coco-2017\",\n",
    "        splits=splits,\n",
    "        label_types=[\"detections\"],\n",
    "        max_samples=max_samples,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    # Rename 'validation' split to 'val'\n",
    "    validation_view = dataset.match_tags(\"validation\")\n",
    "    validation_view.tag_samples(\"val\")\n",
    "    validation_view.untag_samples(\"validation\")\n",
    "    \n",
    "    splits.remove(\"validation\")\n",
    "    splits.append(\"val\")\n",
    "\n",
    "    ds_view = dataset.view()\n",
    "\n",
    "    # Manually filter the dataset to samples matching the given catgories\n",
    "    # due to a bug: https://github.com/voxel51/fiftyone/issues/4570\n",
    "    # Workaround based on: https://github.com/voxel51/fiftyone/issues/4570#issuecomment-2392548410\n",
    "    # Unfortunately, the workaround downloads images we don't need and then filters them,\n",
    "    # so we waste a bit of space and network bandwidth.\n",
    "    if categories is not None:\n",
    "        ds_view = ds_view.filter_labels(\"ground_truth\", fo.ViewField(\"label\").is_in(categories))\n",
    "\n",
    "    # Export in YOLOv8 format.\n",
    "    # According to https://github.com/voxel51/fiftyone/issues/3392#issuecomment-1666520356,\n",
    "    # splits must be exported separately.\n",
    "    export_dir = os.path.join(IMAGES_PATH, directory)\n",
    "    for split in splits:\n",
    "        view = ds_view.match_tags(split)\n",
    "        view.export(\n",
    "            export_dir=export_dir,\n",
    "            dataset_type=dataset_format,\n",
    "            split=split,\n",
    "            classes=categories,\n",
    "        )\n",
    "        print(f\"Split '{split}' exported to '{export_dir}/{split}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_coco2017(max_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip dataset zip file (Not used anymore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip data files into the specified folder\n",
    "def unzip_data(zip_file, folder_path):\n",
    "    # created folder if it does not exist\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # unzip the contents of the zip file to the destination folder\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(folder_path)\n",
    "\n",
    "    print(f\"{zip_file} unzip to {folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined folder for datasets \n",
    "COMBINED_FOLDER = os.path.join(DATAFOLDER, 'combined-images')\n",
    "\n",
    "if not os.path.exists(COMBINED_FOLDER):\n",
    "    os.makedirs(COMBINED_FOLDER)\n",
    "\n",
    "def combine_and_rename(src_folder, dataset_name, class_offset):\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        img_src_folder = os.path.join(src_folder, split, 'images')\n",
    "        lbl_src_folder = os.path.join(src_folder, split, 'labels')\n",
    "\n",
    "        img_dest_folder = os.path.join(COMBINED_FOLDER, split, 'images')\n",
    "        lbl_dest_folder = os.path.join(COMBINED_FOLDER, split, 'labels')\n",
    "\n",
    "        if not os.path.exists(img_dest_folder):\n",
    "            os.makedirs(img_dest_folder)\n",
    "        if not os.path.exists(lbl_dest_folder):\n",
    "            os.makedirs(lbl_dest_folder)\n",
    "\n",
    "        img_files = sorted(os.listdir(img_src_folder))\n",
    "        lbl_files = sorted(os.listdir(lbl_src_folder))\n",
    "\n",
    "        for i, img_file in enumerate(img_files):\n",
    "            lbl_file = lbl_files[i]\n",
    "\n",
    "            new_img_name = f\"{dataset_name}-img-{i+1}.jpg\"\n",
    "            new_lbl_name = f\"{dataset_name}-img-{i+1}.txt\"\n",
    "\n",
    "            img_src_path = os.path.join(img_src_folder, img_file)\n",
    "            lbl_src_path = os.path.join(lbl_src_folder, lbl_file)\n",
    "\n",
    "            img_dest_path = os.path.join(img_dest_folder, new_img_name)\n",
    "            lbl_dest_path = os.path.join(lbl_dest_folder, new_lbl_name)\n",
    "\n",
    "            # Read and modify label file content (adjust class IDs)\n",
    "            with open(lbl_src_path, 'r') as lbl_file:\n",
    "                lines = lbl_file.readlines()\n",
    "\n",
    "            with open(lbl_dest_path, 'w') as new_lbl_file:\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    class_id = int(parts[0]) + class_offset\n",
    "                    new_line = f\"{class_id} \" + \" \".join(parts[1:]) + \"\\n\"\n",
    "                    new_lbl_file.write(new_line)\n",
    "\n",
    "            # Copy the image file\n",
    "            shutil.copy(img_src_path, img_dest_path)\n",
    "\n",
    "            # Augmentation logic\n",
    "            # Only augment underrepresented classes based on `class_occurrences`\n",
    "            # with open(lbl_src_path, 'r') as lbl_file:\n",
    "            #     for line in lbl_file.readlines():\n",
    "            #         class_id = int(line.split()[0]) + class_offset\n",
    "            #         # If the class ID has fewer samples, augment the image\n",
    "            #         if class_occurrences[class_id] < 500:  # Define threshold for underrepresented classes\n",
    "            #             augment_image(img_src_path, lbl_src_path, img_dest_folder, i, dataset_name)\n",
    "\n",
    "            #print(f\"Moved {img_file} -> {new_img_name} with updated labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create yaml file for combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join(COMBINED_FOLDER, 'train', 'images')\n",
    "VAL_PATH = os.path.join(COMBINED_FOLDER, 'valid', 'images')\n",
    "TEST_PATH = os.path.join(COMBINED_FOLDER, 'test', 'images')\n",
    "OUTPUT_PATH = os.path.join(COMBINED_FOLDER, 'data.yaml')\n",
    "\n",
    "\n",
    "def load_yaml(yaml_path):\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def combine_yaml_new(yaml_files, class_offsets):\n",
    "    combined_data = {\n",
    "        'train': TRAIN_PATH,\n",
    "        'val': VAL_PATH,\n",
    "        'test': TEST_PATH,\n",
    "        'names': []  # will hold class names at the right index positions\n",
    "    }\n",
    "\n",
    "    # Loop through each yaml file and its corresponding class offset\n",
    "    for i, yaml_file in enumerate(yaml_files):\n",
    "        data = load_yaml(yaml_file)\n",
    "        offset = class_offsets[i]  # get the offset for the current dataset\n",
    "\n",
    "        # Ensure combined_data['names'] list is large enough\n",
    "        max_index = offset + len(data['names']) - 1\n",
    "        while len(combined_data['names']) <= max_index:\n",
    "            combined_data['names'].append(None)\n",
    "\n",
    "        # Insert class names at the correct index positions\n",
    "        for j, class_name in enumerate(data['names']):\n",
    "            combined_data['names'][offset + j] = class_name\n",
    "\n",
    "    # Fill any None entries with default values (optional, in case something was missed)\n",
    "    combined_data['names'] = [name if name is not None else 'unknown' for name in combined_data['names']]\n",
    "\n",
    "    combined_data['nc'] = len(combined_data['names'])  # set the number of unique classes\n",
    "\n",
    "    # Write combined data to a new YAML file\n",
    "    with open(OUTPUT_PATH, 'w+') as yaml_f:\n",
    "        yaml.dump(combined_data, yaml_f)\n",
    "\n",
    "    print(f\"Combined YAML file created at {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Data Imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_class_occurrences(folder_path):\n",
    "    label_files = []\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        lbl_folder = os.path.join(folder_path, split, 'labels')\n",
    "        for file in os.listdir(lbl_folder):\n",
    "            label_files.append(os.path.join(lbl_folder, file))\n",
    "\n",
    "    class_counter = Counter()\n",
    "    for lbl_file in label_files:\n",
    "        with open(lbl_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                class_id = int(line.split()[0])\n",
    "                class_counter[class_id] += 1\n",
    "\n",
    "    print(f\"Class Occurrences: {class_counter}\")\n",
    "    return class_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Imbalanced Data (Does not work right now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the augmentation pipeline\n",
    "AUGMENTATIONS = [\n",
    "    A.HorizontalFlip(p=1.0),\n",
    "    A.Rotate(limit=20, p=1.0),\n",
    "    A.RandomBrightnessContrast(p=1.0),\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=20, p=1.0)\n",
    "]\n",
    "\n",
    "# Augment image function\n",
    "def augment_image(image_path, label_path, aug_folder, index, dataset_name):\n",
    "    image = cv2.imread(image_path)\n",
    "    img_height, img_width = image.shape[:2]\n",
    "\n",
    "    # Read bounding box labels\n",
    "    with open(label_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for i, aug in enumerate(AUGMENTATIONS):\n",
    "        augmented = aug(image=image)\n",
    "        aug_image = augmented['image']\n",
    "\n",
    "        # Save the augmented image with a new name\n",
    "        aug_img_name = f\"{dataset_name}-img-{index+1}-aug-{i+1}.jpg\"\n",
    "        aug_img_path = os.path.join(aug_folder, aug_img_name)\n",
    "        cv2.imwrite(aug_img_path, aug_image)\n",
    "\n",
    "        # Save the corresponding augmented label file\n",
    "        aug_lbl_name = f\"{dataset_name}-img-{index+1}-aug-{i+1}.txt\"\n",
    "        aug_lbl_path = os.path.join(aug_folder, aug_lbl_name)\n",
    "        with open(aug_lbl_path, 'w') as aug_label_file:\n",
    "            aug_label_file.writelines(lines)\n",
    "\n",
    "    print(f\"Augmented image and label saved to {aug_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune the YOLO model with new dataset\n",
    "# epochs=5 for testing purposes\n",
    "def fine_tune(model, yaml_path, epochs=5, imgsz=640, batch=16, device=None):\n",
    "    # model.train(data=yaml_path, epochs=epochs, imgsz=imgsz, batch=batch)\n",
    "    # prepare the arguments for model.train\n",
    "    train_kwargs = {\n",
    "        'data': yaml_path,\n",
    "        'epochs': epochs, \n",
    "        'imgsz': imgsz,\n",
    "        'batch': batch\n",
    "    }\n",
    "\n",
    "    # include 'deivce' only if its not none \n",
    "    if device is not None: \n",
    "        train_kwargs['device'] = device\n",
    "\n",
    "    # train model \n",
    "    model.train(**train_kwargs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model \n",
    "def save_model(model):\n",
    "    model.save('yolo_fine_tuned.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Datasets (Will create a new section for this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip parcel images dataset into the 'parcel-images' folder\n",
    "unzip_data(os.path.join(DATAFOLDER, \"parcel.v1i.yolov8.zip\"), os.path.join(DATAFOLDER, \"parcel-images\"))\n",
    "\n",
    "# unzip the gun images dataset into the 'gun-images' folder\n",
    "unzip_data(os.path.join(DATAFOLDER, \"Weapon classification.v2i.yolov8.zip\"), os.path.join(DATAFOLDER, \"gun-images\"))\n",
    "\n",
    "# unzip the human images dataset into the 'human-images' folder\n",
    "unzip_data(os.path.join(DATAFOLDER, \"Crowd Detection.v3i.yolov8.zip\"), os.path.join(DATAFOLDER, \"human-images\"))\n",
    "\n",
    "# dataset source folder \n",
    "parcel_folder = os.path.join(DATAFOLDER, \"parcel-images\")\n",
    "gun_folder = os.path.join(DATAFOLDER, \"gun-images\")\n",
    "human_folder = os.path.join(DATAFOLDER, \"human-images\")\n",
    "\n",
    "# Calculate class occurrences \n",
    "# class_occurrences = count_class_occurrences(COMBINED_FOLDER)\n",
    "# print(f\"Before balancing data: {class_occurrences}\")\n",
    "\n",
    "# combine dataset with augmentation for underrepresented classes\n",
    "combine_and_rename(parcel_folder, 'parcel', class_offset=0)\n",
    "combine_and_rename(gun_folder, 'gun', class_offset=1)\n",
    "combine_and_rename(human_folder, 'human', class_offset=3)\n",
    "\n",
    "# print(f\"After balancing data: {count_class_occurrences(COMBINED_FOLDER)}\")\n",
    "\n",
    "# path to yaml configuration for parcel images and gun images\n",
    "parcel_yaml = os.path.join(DATAFOLDER, \"parcel-images\", \"data.yaml\")\n",
    "gun_yaml = os.path.join(DATAFOLDER, \"gun-images\", \"data.yaml\")\n",
    "human_yaml = os.path.join(DATAFOLDER, \"human-images\", \"data.yaml\")\n",
    "\n",
    "class_offsets = [0, 1, 3]\n",
    "yaml_list = [parcel_yaml, gun_yaml, human_yaml]\n",
    "\n",
    "combine_yaml_new(yaml_list, class_offsets)\n",
    "\n",
    "count_class_occurrences(COMBINED_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Dataset Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data source folder \n",
    "gun_folder = os.path.join(DATAFOLDER, \"gun-images\")\n",
    "\n",
    "# combine dataset \n",
    "combine_and_rename(gun_folder, 'gun', class_offset=0)\n",
    "\n",
    "gun_yaml = os.path.join(DATAFOLDER, \"gun-images\", \"data.yaml\")\n",
    "\n",
    "class_offsets = [0]\n",
    "yaml_list = [gun_yaml]\n",
    "\n",
    "combine_yaml_new(yaml_list, class_offsets)\n",
    "\n",
    "count_class_occurrences(COMBINED_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune the YOLO model with combined dataset images \n",
    "fined_tuned_model = fine_tune(model, os.path.join(COMBINED_FOLDER, \"data.yaml\"))\n",
    "\n",
    "#fined_tuned_model = fine_tune(model, gun_yaml)\n",
    "\n",
    "# save the model\n",
    "save_model(fined_tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    model = YOLO(model_name)\n",
    "    return model\n",
    "\n",
    "fined_tuned_model = load_model('yolo_fine_tuned.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def test_model(model, img_path, conf=0.25):\n",
    "    # Perform object detection\n",
    "    results = model(img_path, conf=conf)\n",
    "\n",
    "    # retrieve the annotated image (with bounding boxes and labels)\n",
    "    annotated_img = results[0].plot()\n",
    "\n",
    "    # display the image\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(annotated_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "test_model(fined_tuned_model, os.path.join(FOLDER_PATH, 'sentinel_model_gen', 'guy_w_box.png'))\n",
    "test_model(fined_tuned_model, os.path.join(FOLDER_PATH, 'sentinel_model_gen', 'guy.png'))\n",
    "test_model(fined_tuned_model, os.path.join(FOLDER_PATH, 'sentinel_model_gen', 'guy_w_gun.png'))\n",
    "test_model(fined_tuned_model, os.path.join(FOLDER_PATH, 'sentinel_model_gen', 'guy_w_gun_2.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model to TFLite Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model to TFLite for use in the detection system \n",
    "def export_model(model): \n",
    "    model.export(format='tflite')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
